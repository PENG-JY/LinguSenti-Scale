[
  {
    "objectID": "nlp.html",
    "href": "nlp.html",
    "title": "Natural Language Processing",
    "section": "",
    "text": "Milestone 2 Deliverable\n\n\n\nThis page is populated during Milestone 2 (Week 5) with NLP findings."
  },
  {
    "objectID": "nlp.html#overview",
    "href": "nlp.html#overview",
    "title": "Natural Language Processing",
    "section": "Overview",
    "text": "Overview\nThis page presents NLP analysis addressing [3-4] NLP business questions through sentiment analysis, topic modeling, and text mining."
  },
  {
    "objectID": "nlp.html#business-question-1-how-do-emotional-tones-in-relationship-discussions-vary-across-temporal-patterns",
    "href": "nlp.html#business-question-1-how-do-emotional-tones-in-relationship-discussions-vary-across-temporal-patterns",
    "title": "Natural Language Processing",
    "section": "Business Question 1: How do emotional tones in relationship discussions vary across temporal patterns?",
    "text": "Business Question 1: How do emotional tones in relationship discussions vary across temporal patterns?\nQuestion: How do emotional tones in Reddit relationship discussions change across different temporal patterns (hour of day, weekday, and month), and what do these shifts reveal about user commenting behavior and community sentiment dynamics?\n\nFindings\n  \nKey Insights:\n\nNegative emotions (especially fear and anger) are slightly elevated during late-night hours, suggesting that emotionally intense posts tend to occur after midnight.\nPositive emotions increase during afternoon and evening periods, indicating that daytime discussions are more constructive and solution-oriented.\nSundays exhibit higher negative and fear-related emotion levels, while Wednesdays show the strongest positive sentiment, reflecting mid-week stability and weekend emotional volatility.\nPositive emotions peak between March and May, accompanied by lower negative sentiment, suggesting a seasonal uplift in emotional tone during the spring months."
  },
  {
    "objectID": "nlp.html#business-question-2-what-are-the-most-common-themes-from-topic-modeling-lda-or-bertopic-in-relationship-stories-e.g.-trust-issues-infidelity-family-pressure",
    "href": "nlp.html#business-question-2-what-are-the-most-common-themes-from-topic-modeling-lda-or-bertopic-in-relationship-stories-e.g.-trust-issues-infidelity-family-pressure",
    "title": "Natural Language Processing",
    "section": "Business Question 2: : What are the most common themes from topic modeling (LDA or BERTopic) in relationship stories (e.g., trust issues, infidelity, family pressure)?",
    "text": "Business Question 2: : What are the most common themes from topic modeling (LDA or BERTopic) in relationship stories (e.g., trust issues, infidelity, family pressure)?\nQuestion: Based on topic modeling results, what are the most common patterns or themes people discuss in relationship stories (e.g., trust issues, infidelity, emotional disconnect, family interference)?\n\nFindings\nKey Insights:\nHere are the 15 identified topics from the LDA analysis, each described by their most representative keywords. These keywords suggest recurring themes and concerns in relationship-related texts:\n\nTopic 0 – confusion, uncertainty, hesitation in dating dont know, guard, maybe, mystery, what, keep, interest\nTopic 1 – texting dynamics, ghosting, interest loss follow, wait, response, start, message, lose, effort\nTopic 2 – rejection, desire, emotional struggle thought, want, reject, life, hard, accept\nTopic 3 – friendzone, attraction, assumptions safe, assume, never attract, met, friend, situation\nTopic 4 – sexual pressure, hesitation, asking consent ask, stop, think, want, great, sex\nTopic 5 – loyalty, lying, effort in relationship loyal, never lie, stay, effort, communicate\nTopic 6 – emotional manipulation, apology cycles manipul, apologize, hurt, change, promise\nTopic 7 – external opinions, self-esteem, judgment everyon, opinion, wrong, blame, better\nTopic 8 – infidelity, trust issues, jealousy cheat, talk, jealous, faith, betray\nTopic 9 – self-worth, validation, loneliness worth, lonely, need, validate, enough\nTopic 10 – sexual confusion, boundaries confus, stop, sex, unsure, chang\nTopic 11 – family interference, privacy mom, doctor, behind, back, health\nTopic 12 – ghosting, online dating, lack of closure match, multiple, date, disappear, effort\nTopic 13 – emotional dependence, clinginess, abandonment need, constant, reassure, left\nTopic 14 – future planning, commitment anxiety plan, future, scare, commit, big step"
  },
  {
    "objectID": "nlp.html#business-question-3-do-writing-style-and-emotional-vocabulary-influence-community-engagement",
    "href": "nlp.html#business-question-3-do-writing-style-and-emotional-vocabulary-influence-community-engagement",
    "title": "Natural Language Processing",
    "section": "Business Question 3: Do writing style and emotional vocabulary influence community engagement?",
    "text": "Business Question 3: Do writing style and emotional vocabulary influence community engagement?\nQuestion: To what extent do writing-style features (post length, emotional vocabulary, question usage, and readability) predict community engagement measured by the number of comments?\n\nFindings\n\nKey Insights:\n\nEmotional vocabulary density shows very weak relationship with comment count (corr ≈ 0.014), suggesting that using more emotional words does not meaningfully increase engagement.\nPosts with more tokens receive slightly more comments (corr ≈ 0.087), making post length the strongest predictor among the examined features.\nQuestion marks correlate marginally with engagement (corr ≈ 0.081), indicating that asking questions may offer a slight boost to response activity.\nReadability score shows insignificant correlation with engagement (corr ≈ 0.017), implying that writing complexity does not shape community response."
  },
  {
    "objectID": "nlp.html#business-question-4-what-early-linguistic-markers-can-signal-whether-a-post-will-receive-high-engagement",
    "href": "nlp.html#business-question-4-what-early-linguistic-markers-can-signal-whether-a-post-will-receive-high-engagement",
    "title": "Natural Language Processing",
    "section": "Business Question 4: What early linguistic markers can signal whether a post will receive high engagement?",
    "text": "Business Question 4: What early linguistic markers can signal whether a post will receive high engagement?\nQuestion: Can we identify specific linguistic patterns—such as word choice, emotional tone, or message structure—that reliably predict whether a Reddit relationship post will receive high community engagement (comments)?\n\nFindings\n\nKey Insights:\n\nHigh- and low-engagement posts share similar core vocabulary, meaning engagement is not driven by unique or rare keywords.\nBut high-engagement posts use emotional-state verbs (“feel”, “want”, “dont”, “know”) more frequently, indicating stronger emotional disclosure.\nThey also contain more question marks, reflecting uncertainty, problem-solving needs, and explicit invitations for advice.\nOverall, posts that read as vulnerable, emotionally expressive, and actively seeking guidance consistently draw more comments."
  },
  {
    "objectID": "nlp.html#extended-sentiment-analysis-anger-vs.-joy",
    "href": "nlp.html#extended-sentiment-analysis-anger-vs.-joy",
    "title": "Natural Language Processing",
    "section": "Extended Sentiment Analysis: Anger vs. Joy",
    "text": "Extended Sentiment Analysis: Anger vs. Joy\n\nOverall Sentiment Distribution\n\nUsing the NRC emotion lexicon, we computed emotion density for each Reddit comment—defined as the proportion of tokens associated with a given emotion. The histogram shows that both anger and joy densities are highly concentrated near zero, with long right-tailed distributions. This pattern indicates that most comments contain very few explicit emotional keywords, while a smaller subset exhibits substantially higher emotional intensity. Joy displays a broader spread than anger, suggesting that positive emotional expressions appear more frequently and with greater variability across the dataset. This overall distribution provides the baseline context for examining temporal and subgroup variations in emotional tone.\n\n\nSentiment by Subreddit\nOur dataset is drawn exclusively from the subreddit r/relationship_advice, meaning all posts come from a single community. As a result, sentiment cannot be compared across multiple subreddits, and subreddit-level variation is not applicable in this context. Instead, our sentiment analysis focuses on within-subreddit patterns—specifically how emotional expression varies across time and across individual posts. This ensures that all observed sentiment differences are driven by user behavior rather than differences in community norms or discussion environments."
  },
  {
    "objectID": "nlp.html#summary",
    "href": "nlp.html#summary",
    "title": "Natural Language Processing",
    "section": "Summary",
    "text": "Summary\n\nAnswers to NLP Business Questions\n\nHow do emotional tones in relationship discussions vary across temporal patterns?: Emotional tones show consistent temporal structure: negative emotions (especially fear and anger) increase modestly during late-night hours, while positive emotions rise during afternoon and evening periods. Sundays exhibit higher negative sentiment, whereas Wednesdays show the strongest positive tone. Positive emotions also peak between March and May, suggesting a seasonal uplift in emotional expression during the spring months.\nWhat are the most common themes from topic modeling (LDA or BERTopic) in relationship stories (e.g., trust issues, infidelity, family pressure)?: LDA topic modeling revealed several dominant themes in relationship stories, with the most common centered around infidelity and trust issues, communication problems (texting, ghosting), emotional insecurity, and modern dating challenges. These themes emerged naturally from keyword clusters and represent the recurring concerns that drive users to seek advice.\nDo writing style and emotional vocabulary influence community engagement?: Emotional vocabulary and writing-style features show only weak associations with engagement, indicating that comment volume is driven far more by content than by sentiment or stylistic choices.\nWhat early linguistic markers signal high engagement?: Early linguistic markers of high engagement are subtle rather than structural. High- and low-engagement posts have nearly identical length and lexical diversity, but high-engagement content shows a modestly higher use of question marks and slightly stronger prevalence of emotional-state verbs (“feel”, “want”, “dont”, “know”), indicating a greater tendency toward explicit uncertainty, emotional articulation, and invitation for interaction rather than differences in overall textual complexity.\n\n\n\n\nBusiness Implications\n\nPeak negative emotion periods (late night, Sundays) indicate when users are most likely to seek urgent or emotionally charged support. Platforms or moderators could allocate resources to these time windows to improve response quality and community safety.\nDominant themes such as infidelity, trust breakdown, communication failure, and insecurity highlight core user pain points. These insights can guide targeted content strategies, automated FAQ suggestions, or personalized support tools addressing high-frequency relationship stressors.\nWeak influence of writing style on engagement suggests that platform engagement is content-driven rather than presentation-driven. This reduces emphasis on linguistic coaching and instead supports surfacing posts with substantive relational dilemmas.\nEarly indicators of high engagement—greater use of emotional-state verbs and question-oriented phrasing—suggest opportunities for features that detect posts requiring community attention. Automated triage or “potential high-impact post” flags could help moderators or support agents prioritize emotionally complex cases.\n\nOverall, these findings reveal predictable emotional rhythms, recurring thematic concerns, and subtle linguistic signals that can inform community management, content recommendation, and user-support strategies for relationship-focused online platforms.\n\n\n\n\n\n\n\nTip\n\n\n\nAll NLP code is in code/nlp/ directory."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Understanding Emotional Dynamics in Online Relationship Discussions",
    "section": "",
    "text": "Jiayi Peng\nKexin Lyu\nStacy Che\nYanan Wu"
  },
  {
    "objectID": "index.html#team-members",
    "href": "index.html#team-members",
    "title": "Understanding Emotional Dynamics in Online Relationship Discussions",
    "section": "",
    "text": "Jiayi Peng\nKexin Lyu\nStacy Che\nYanan Wu"
  },
  {
    "objectID": "index.html#project-overview",
    "href": "index.html#project-overview",
    "title": "Understanding Emotional Dynamics in Online Relationship Discussions",
    "section": "Project Overview",
    "text": "Project Overview\nHigh-Level Problem Statement:\nHow do linguistic patterns, emotional expressions, and temporal posting behaviors shape community engagement and sentiment dynamics within Reddit relationship discussions?\n\nDataset\n\nSource: Reddit Comments and Submissions\nTime Period: June 2023 – July 2024\nSubreddits: r/relationship_advice\nScale: ~9.8 million total rows (8.7M comments + 1.1M submissions)\nSize: ~1.83 GB\n\n\n\nBusiness Questions\nWe address 10 business questions spanning three analytical approaches:\nExploratory Data Analysis (EDA):\n\nHow do posting behaviors vary by season, hour, and day of week?\nHow do post lengths and engagement (score / comment count) correlate over time?\nWhich types of posts (“confession”, “breakup”, “family”, “marriage”, etc.) receive the most comments on average?\n\nNatural Language Processing (NLP):\n\nHow do emotional tones in Reddit relationship discussions change across different temporal patterns (hour of day, weekday, and month), and what do these shifts reveal about user commenting behavior and community sentiment dynamics?\nWhat are the most common themes from topic modeling (LDA or BERTopic) in relationship stories (e.g., trust issues, infidelity, family pressure)?\nDo writing style and emotional vocabulary influence community engagement?\nWhat early linguistic markers can signal whether a post will receive high engagement?\n\nMachine Learning (ML):\n\nCan we predict whether a Reddit comment will be “controversial”?\nCan we predict whether a Reddit relationship post will receive high engagement (top 25% comment count)?\nCan we predict the daily posting volume of r/relationship_advice using temporal and engagement-driven signals?\n\nSee BUSINESS_QUESTIONS.md for detailed technical approaches."
  },
  {
    "objectID": "index.html#methodology",
    "href": "index.html#methodology",
    "title": "Understanding Emotional Dynamics in Online Relationship Discussions",
    "section": "Methodology",
    "text": "Methodology\n\nData Processing Infrastructure\n\nPlatform: Apache Spark cluster on AWS EC2\nProcessing: Distributed computing with PySpark\nStorage: Amazon S3 for data lake architecture\nScale: Processing hundreds of millions of rows\n\n\n\nAnalysis Pipeline\n\nData Acquisition & Filtering (Milestone 0)\n\nCopy full Reddit dataset from source bucket\nFilter to subreddits of interest\nGenerate dataset statistics\n\nExploratory Data Analysis (Milestone 1) → EDA Page\n\nTemporal posting patterns (season, hour, weekday)\nPost length vs. engagement over time\nEngagement differences across relationship post types\n\nNatural Language Processing (Milestone 2) → NLP Page\n\nEmotional tone shifts across temporal cycles\nTopic modeling of common relationship themes\nLinguistic features associated with high engagement\n\nMachine Learning (Milestone 3) → ML Page\n\nPredicting controversial comments\nPredicting high-engagement posts\nForecasting daily posting volume\n\nFinal Analysis (Milestone 4) → Conclusion\n\nIntegrated findings\nPractical insights and recommendations"
  },
  {
    "objectID": "index.html#key-findings-preview",
    "href": "index.html#key-findings-preview",
    "title": "Understanding Emotional Dynamics in Online Relationship Discussions",
    "section": "Key Findings Preview",
    "text": "Key Findings Preview\n\nMajor Insights\n\nEngagement patterns are shaped mainly by temporal rhythms and relational stakes, with evening and summertime peaks and substantially higher interaction on emotionally intensive topics such as marriage and breakups, while surface-level text features like length show only weak associations.\nEmotional expression and relational stakes are the strongest drivers of engagement in relationship discussions, as posts that reveal vulnerability, seek guidance, or address major issues such as trust, infidelity, or commitment consistently generate the most interaction and shape the community’s emotional tone.\nMachine learning models reveal that community engagement, conflict likelihood, and daily activity levels can be reliably predicted from simple behavioral, linguistic, and temporal signals, showing that much of the subreddit’s interaction dynamics follow consistent and learnable patterns.\n\n\n\nBusiness Impact\nOur analysis shows that engagement and emotional dynamics in relationship-focused Reddit communities follow consistent linguistic, temporal, and behavioral patterns that can be quantified and predicted. By combining EDA, NLP, and ML approaches, we uncover when users are most active, which emotional tones resonate with the community, and which types of posts are most likely to drive discussion or conflict. These insights translate into actionable strategies for platform managers and moderators: identifying high-risk threads earlier, prioritizing resources during expected surges, promoting supportive interactions, and ranking content to encourage constructive engagement. Overall, the findings provide a data-driven foundation for improving community health, enhancing user experience, and supporting moderation and platform design decisions."
  },
  {
    "objectID": "index.html#navigation",
    "href": "index.html#navigation",
    "title": "Understanding Emotional Dynamics in Online Relationship Discussions",
    "section": "Navigation",
    "text": "Navigation\nUse the navigation bar above to explore:\n\nEDA: Exploratory data analysis with statistical insights and temporal patterns\nNLP: Natural language processing analysis including sentiment and topics\nML: Machine learning models and predictions\nConclusion: Summary of findings and recommendations"
  },
  {
    "objectID": "index.html#repository",
    "href": "index.html#repository",
    "title": "Understanding Emotional Dynamics in Online Relationship Discussions",
    "section": "Repository",
    "text": "Repository\n\nGitHub: https://github.com/gu-dsan6000/fall-2025-project-team-17/\nDocumentation: All code, data outputs, and analysis documentation available in repository\n\n\nLast updated: 12/02/2025"
  },
  {
    "objectID": "conclusion.html",
    "href": "conclusion.html",
    "title": "Conclusion and Recommendations",
    "section": "",
    "text": "Milestone 4 Deliverable\n\n\n\nThis page is populated during Milestone 4 (Week 8) - Final Submission."
  },
  {
    "objectID": "conclusion.html#executive-summary",
    "href": "conclusion.html#executive-summary",
    "title": "Conclusion and Recommendations",
    "section": "Executive Summary",
    "text": "Executive Summary\nThis project analyzes 9.8 million Reddit comments and submissions from r/relationship_advice to understand how linguistic patterns, emotional expression, and temporal posting behaviors shape community engagement and sentiment dynamics. Using distributed processing on Apache Spark, we performed large-scale EDA to uncover temporal cycles in posting behavior and topic-driven differences in engagement. NLP methods including NRC emotion analysis, topic modeling, and linguistic feature extraction revealed that emotional intensity, vulnerability, and high-stakes relationship themes drive the strongest community reactions. Machine learning models further demonstrated that controversy, high engagement, and daily activity levels can be reliably predicted from simple behavioral and linguistic features, indicating consistent and learnable patterns in community interaction.\nTogether, these findings provide a comprehensive view of how relationship discussions evolve on Reddit and offer actionable insights for moderation strategy, content ranking, and user support. The project shows that emotional tone, relational stakes, and posting context rather than text length or rarity are the primary forces shaping engagement and sentiment in this online advice-seeking community."
  },
  {
    "objectID": "conclusion.html#answers-to-all-10-business-questions",
    "href": "conclusion.html#answers-to-all-10-business-questions",
    "title": "Conclusion and Recommendations",
    "section": "Answers to All 10 Business Questions",
    "text": "Answers to All 10 Business Questions\n\nEDA Questions\n\nHow do posting behaviors vary by season, hour, and day of week?: Posting activity shows clear seasonal and daily cycles, peaking during summer months and during evening hours in major Western time zones, with slightly higher engagement early in the week.\nHow do post lengths and engagement (score / comment count) correlate over time?: Post length is positively correlated with engagement, but only weakly. Longer posts receive more comments on average than short posts, yet the overall correlation between length and score/comments remains below 0.1, suggesting other factors primarily drive user responses.\nWhich types of posts (“confession”, “breakup”, “family”, “marriage”, etc.) receive the most comments on average?: Among all relationship-related post types, “marriage” discussions receive by far the highest engagement, with an average of 13.88 comments per post — more than double that of any other category. Posts about breakups and dating follow, each averaging around 6 comments, indicating moderate but consistent community interaction.\n\n\n\nNLP Questions\n\nHow do emotional tones in relationship discussions vary across temporal patterns?: Emotional tones show consistent temporal structure: negative emotions (especially fear and anger) increase modestly during late-night hours, while positive emotions rise during afternoon and evening periods. Sundays exhibit higher negative sentiment, whereas Wednesdays show the strongest positive tone. Positive emotions also peak between March and May, suggesting a seasonal uplift in emotional expression during the spring months.\nWhat are the most common themes from topic modeling (LDA or BERTopic) in relationship stories (e.g., trust issues, infidelity, family pressure)?: LDA topic modeling revealed several dominant themes in relationship stories, with the most common centered around infidelity and trust issues, communication problems (texting, ghosting), emotional insecurity, and modern dating challenges. These themes emerged naturally from keyword clusters and represent the recurring concerns that drive users to seek advice.\nDo writing style and emotional vocabulary influence community engagement?: Emotional vocabulary and writing-style features show only weak associations with engagement, indicating that comment volume is driven far more by content than by sentiment or stylistic choices.\nWhat early linguistic markers signal high engagement?: High-engagement posts exhibit clear linguistic signatures: they contain more emotional verbs (“feel”, “want”, “dont”), are longer and richer in unique vocabulary, and include more direct questions. These patterns suggest that self-disclosure, emotional depth, and explicit advice-seeking strongly predict higher community engagement on relationship subreddits.\n\n\n\nML Questions\n\nCan we use comment-level metadata and simple text-derived features to predict whether a Reddit comment in r/relationship_advice will be controversial (i.e., produce disagreement reflected by Reddit’s controversiality flag)?: Yes. Using metadata and simple linguistic features, a Logistic Regression model achieves AUC ≈ 0.76. Key predictors include comment depth, awards, and emotionally expressive writing (punctuation, short opinionated phrasing).\nCan early linguistic and behavioral signals in a relationship-focused Reddit post help us predict which posts will spark large-scale community engagement and conversation? Yes. A lightweight, class-balanced model predicts high-engagement posts with AUC ≈ 0.65, successfully identifying a majority of posts in the top 25% comment-count group. Features related to community interaction (unique commenters, controversiality) and expressive language contribute meaningfully.\nCan we use historical posting trends, time-based seasonality, and lagged behavioral patterns to forecast how many posts the subreddit will receive each day?: Yes. Using lag-based and rolling temporal features, Ridge Regression achieves R² ≈ 0.56, showing that over half of day-to-day variation in posting activity can be explained by historical behavioral cycles. Yesterday’s volume, short-term weekly cycles, and rolling 14-30 day trends matters most."
  },
  {
    "objectID": "conclusion.html#major-findings",
    "href": "conclusion.html#major-findings",
    "title": "Conclusion and Recommendations",
    "section": "Major Findings",
    "text": "Major Findings\n\nKey Insight 1: Engagement Follows Clear Temporal and Topical Patterns\nUser activity and engagement show strong temporal rhythms, with peaks during evening hours and summer months, and certain topics such as marriage and breakups drawing significantly higher participation. Text length shows only weak correlation with engagement, indicating that the emotional significance of the topic matters more than verbosity.\nBusiness Impact:\nUnderstanding when users are most active and which topics reliably generate discussion allows moderators and platform managers to better allocate resources, anticipate high-traffic periods, and design content strategies that encourage healthy participation. Highlighting high-stakes topics during peak hours can improve community responsiveness, while targeted moderation can help prevent overload during surges.\n\n\nKey Insight 2: Emotional Expression and High-Stakes Themes Drive Community Interaction\nNLP analyses show that emotionally expressive posts, particularly those involving trust, uncertainty, infidelity, or long-term commitment, attract stronger reactions and shape overall community sentiment. Spring months and mid-week periods show more positive tone, while late-night and weekend discussions are more negative or fear-driven.\nBusiness Impact:\nRecognizing which emotional tones and relational themes trigger strong engagement enables platforms to guide users toward more constructive interactions. Moderators can monitor emotionally intense periods more closely, while recommendation systems can surface supportive or informative content when users are likely to be distressed. This helps maintain a healthier emotional climate within the community.\n\n\nKey Insight 3: Engagement, Conflict, and Activity Can Be Predicted Reliably\nMachine learning models demonstrate that conflict likelihood, high engagement, and daily posting volume can be predicted using simple behavioral, linguistic, and temporal features. These consistent and learnable patterns allow early detection of controversial threads and accurate forecasting of community activity.\nBusiness Impact:\nPredictive signals provide a powerful tool for proactive moderation and platform planning. Moderators can identify emerging conflicts earlier, allocate attention to posts likely to go viral, and prepare for high-volume days. Platforms can use these predictions to improve content ranking, reduce the spread of conflict spirals, and optimize system resources such as NLP pipelines during expected surges."
  },
  {
    "objectID": "conclusion.html#addressing-the-high-level-problem",
    "href": "conclusion.html#addressing-the-high-level-problem",
    "title": "Conclusion and Recommendations",
    "section": "Addressing the High-Level Problem",
    "text": "Addressing the High-Level Problem\nOriginal Problem Statement:\nHow do linguistic patterns, emotional expressions, and temporal posting behaviors shape community engagement and sentiment dynamics within Reddit relationship discussions?\nHow Our Analysis Addresses It:\nOur multi-stage analysis spanning EDA, NLP, and machine learning systematically decomposes this high-level question into ten focused business questions that collectively reveal how engagement and sentiment emerge and evolve within the community.\nFrom an EDA perspective, we first established the behavioral foundation of the subreddit by examining when users post, how they interact, and which topics attract the most attention. Temporal analyses show that community engagement follows strong daily and seasonal rhythms, while topical comparisons highlight that discussions involving marriage, breakups, or major relationship milestones generate significantly higher engagement than everyday or low-stakes issues. These findings clarify how timing and topic importance shape visibility and participation.\nOur NLP analysis then examined how emotional tone and linguistic content influence community dynamics. NRC-based emotion tracking shows that negative emotions cluster during late-night hours and weekends, whereas positive expressions peak mid-week and during spring months, revealing a temporal structure in emotional climate. Topic modeling identifies the dominant relational themes including trust, infidelity, emotional dependence, and family interference and demonstrates that high-engagement posts tend to be those that are emotionally expressive, vulnerable, or framed as requests for help. Together, these insights explain how emotional language and thematic intensity drive both discussion volume and community sentiment.\nFinally, our machine learning models quantify and predict these dynamics, showing that controversy, engagement, and daily posting volume can be reliably forecast from simple behavioral and linguistic features. These predictive results validate that the subreddit operates with consistent patterns. Emotionally charged writing, complex relational dilemmas, and specific temporal windows all elevate the likelihood of strong community reaction. ML findings also translate these patterns into practical tools for early detection, moderation planning, and activity forecasting.\nBy integrating these perspectives, our analysis demonstrates that Reddit relationship discussions are shaped most strongly by the interplay of posting rhythms, emotional expression, and the relational stakes embedded in users stories. High-engagement threads arise not from text length or uncommon words but from emotionally charged narratives posted during peak activity periods. Sentiment dynamics similarly follow temporal cycles and are anchored in the emotional and thematic content of discussions. In total, our ten analyses spanning user behavior, linguistic structure, emotional tone, and predictive modeling provide a holistic data-driven understanding of how community engagement and sentiment evolve within this online relationship advice ecosystem."
  },
  {
    "objectID": "conclusion.html#business-recommendations",
    "href": "conclusion.html#business-recommendations",
    "title": "Conclusion and Recommendations",
    "section": "Business Recommendations",
    "text": "Business Recommendations\n\nRecommendation 1: Proactive Monitoring of High-Risk Emotional Periods\nBased on:\nOur NLP findings show that fear, anger, and negative sentiment spike late at night and on weekends. ML models demonstrate strong ability to predict controversy (AUC ≈ 0.76), and EDA confirms that emotionally intense topics such as marriage or breakups attract high interaction and conflict.\nAction:\nImplement automated triggers that flag emotionally volatile posts or rapidly growing comment chains during high-risk periods (late-night UTC, weekends). Moderators should be scheduled or alerted during predicted conflict windows. The system can also surface supportive resources (e.g., crisis hotlines, relationship support bots) for users posting high-distress content.\nExpected Impact:\nEarlier intervention reduces escalation, improves community safety, and supports distressed users in real time. Moderation becomes more efficient by focusing attention on the posts most likely to generate conflict.\n\n\nRecommendation 2: Prioritize Emotionally Expressive and Advice-Seeking Posts in Ranking\nBased on:\nNLP results show that high-engagement posts tend to be emotionally expressive, contain question marks, and explicitly seek advice. Topic modeling reveals that posts involving infidelity, commitment, self-worth, and major relational decisions consistently generate richer discussions.\nAction:\nAdjust content ranking or recommendation logic to gently boost posts that display constructive emotional disclosure (e.g., “I feel…”, “I need help with…”) and ask explicit questions. Provide conversation starters or prompts that encourage clarity and vulnerability in user submissions.\nExpected Impact:\nHigher-quality discussions, increased user satisfaction, and greater visibility for users genuinely seeking support. This shifts engagement toward empathic, community-building interactions rather than reactive or conflict-driven content.\n\n\nRecommendation 3: Use Predictive Activity Forecasting to Optimize Moderation and System Resources\nBased on:\nML findings show that daily post volume can be forecast with R² ≈ 0.56 using lag-based and seasonal features. EDA confirms strong circadian and seasonal cycles, with predictable traffic peaks in evenings and summer months.\nAction:\nIntegrate volume forecasts into moderation planning and backend autoscaling. Increase moderator coverage during predicted surges. Adjust compute allocation for NLP pipelines (sentiment, embeddings, topic modeling) based on expected load to maintain performance and reduce costs.\nExpected Impact:\nLower operational overhead, smoother user experience during high-traffic periods, and improved system reliability. Moderators and platform systems can prepare for busy days rather than reacting to unexpected spikes."
  },
  {
    "objectID": "conclusion.html#limitations-and-future-work",
    "href": "conclusion.html#limitations-and-future-work",
    "title": "Conclusion and Recommendations",
    "section": "Limitations and Future Work",
    "text": "Limitations and Future Work\n\nLimitations\n\nKeyword-based labeling for post categories is approximate and may misclassify nuanced cases.\nMitigation: A more robust supervised classifier or transformer-based topic tagger could replace rule-based matching and improve precision.\nLexicon-based sentiment (NRC) captures emotional words but not context or sarcasm.\nMitigation: Future analysis could incorporate contextual models such as RoBERTa, DeBERTa, or domain-adapted emotion classifiers to better understand subtle emotional cues.\nEngagement and controversy models rely on simple metadata and linguistic features.\nMitigation: Additional structural features (thread depth patterns, semantic embeddings, interaction networks) could further strengthen predictive performance.\nSubreddit scope is limited to two relationship-focused communities.\nMitigation: Expanding to more subreddits or cross-platform analysis (e.g., Twitter, Discord) could test the generality of findings.\nDaily volume forecasting explains only part of the variance (R² ≈ 0.56).\nMitigation: Incorporating external signals such as seasonal events, holidays, and news cycles may improve accuracy.\n\n\n\nFuture Work\n\nDevelop transformer-based sentiment and engagement models to improve performance on emotional nuance, conflict detection, and high-engagement prediction.\nBuild richer topic representations using BERTopic, sentence embeddings, and hierarchical clustering to capture deeper narrative structures in relationship stories.\nModel dynamic user interactions by analyzing conversation trees, reply timing, and user-to-user networks to understand how discussions evolve.\nIntegrate anomaly detection to identify unusual emotional surges, viral posts, or sudden shifts in community behavior.\nDeploy real-time dashboards or moderation tools leveraging ML predictions for conflict detection, high-engagement forecasting, and volume forecasting.\n\nThese extensions would deepen our understanding of engagement dynamics and produce more actionable tools for community moderation and platform design."
  },
  {
    "objectID": "conclusion.html#technical-achievements",
    "href": "conclusion.html#technical-achievements",
    "title": "Conclusion and Recommendations",
    "section": "Technical Achievements",
    "text": "Technical Achievements\n\nBig Data Processing\n\nProcessed ~9.8 million Reddit comments and submissions using a distributed Apache Spark cluster.\nPerformed large-scale text cleaning, tokenization, stemming, and NRC-based emotion extraction across &gt;150 million tokens.\nLeveraged Spark SQL and PySpark DataFrames for temporal aggregation, topic categorization, and feature engineering.\nStored all intermediate datasets in AWS S3 (Parquet format), enabling efficient I/O and iterative pipeline development.\nAchieved end-to-end processing times of under 15 minutes per major task (cleaning, NRC emotion join, temporal aggregation) on a 3–5 node Spark cluster.\nSupported downstream NLP and ML tasks—including LDA topic modeling and logistic regression—through scalable vectorization and distributed computation.\n\n\n\nAnalytical Breadth\n\nEDA: Conducted large-scale exploratory analysis using PySpark DataFrames across millions of submissions and comments. Techniques included timestamp conversion (from_unixtime) and temporal feature extraction (hour, weekday, month), high-volume aggregations (groupBy, agg, pivot), correlation analysis between text length and engagement, and keyword-based topic classification using when() + contains()/rlike(). Produced visualization-ready outputs such as hourly heatmaps, topic distributions by year, and scatterplots linking content length to engagement trends.\nNLP: Applied lexicon-based emotion detection using the NRC Emotion Lexicon with stem-aligned tokens to analyze temporal emotional rhythms. Built Spark NLP pipelines (DocumentAssembler → Tokenizer → Normalizer → StopWordsCleaner → Lemmatizer → Finisher) to clean and normalize text at scale. Performed topic modeling with TF-IDF vectorization and Spark MLlib LDA to uncover dominant relationship themes. Ran sentiment analysis (categorical + confidence scores) and engineered linguistic markers (token frequencies, punctuation features, unique-ratio) to evaluate how text structure and emotion relate to engagement dynamics.\nML: Developed Spark ML classification models (Logistic Regression with class weights) to predict controversial comments and high-engagement posts, integrating linguistic, metadata, and behavioral features through VectorAssembler and scaling pipelines. Built a regression modeling suite (Random Forest, Ridge, ElasticNet, XGBoost where applicable) to forecast daily posting volume using lag features, rolling statistics, seasonality indicators, and Fourier terms. Evaluated models with AUC-ROC, F1, RMSE, MAE, and R², achieving stable predictive performance and interpretable feature importance insights."
  },
  {
    "objectID": "conclusion.html#lessons-learned",
    "href": "conclusion.html#lessons-learned",
    "title": "Conclusion and Recommendations",
    "section": "Lessons Learned",
    "text": "Lessons Learned\n\nTechnical Lessons\n\nScalable Spark Processing: Working with multi-million–row Reddit datasets highlighted the importance of distributed execution planning, columnar transformations, and minimizing shuffles. We learned to cache intermediate DataFrames strategically, avoid wide groupBy operations without partitioning, and design queries that leverage Spark’s lazy evaluation to keep jobs efficient and fault-tolerant.\nNLP at Scale: Large-scale text processing required consistent normalization pipelines and careful vocabulary management. We learned that lexicon lookups, token explosion, and TF-IDF vectorization become expensive at scale, so batching transformations inside Spark NLP pipelines and reducing intermediate cardinality (e.g., limiting vocab size, filtering stopwords early) dramatically improves performance and reliability.\nEnd-to-End ML Pipelines: Building classification and regression models in Spark ML taught us the value of fully pipelined workflows: feature engineering → vectorization → scaling → modeling → evaluation. Handling class imbalance (via class weights), ensuring chronological splits for time-series tasks, and using distributed cross-validation were key lessons in developing reproducible and scalable ML systems for real-world big-data environments.\n\n\n\nDomain Lessons\n\nReddit communities exhibit strong temporal and emotional rhythms. Engagement patterns are not random—they follow predictable cycles driven by users’ daily routines, emotional states, and relationship stressors. Understanding these rhythms is essential for interpreting community behavior at scale.\nSocial media analysis requires both breadth and nuance. Large datasets reveal broad structural patterns, but meaningful insights emerge only when combined with careful linguistic and emotional interpretation. Purely quantitative metrics can miss the relational and psychological depth that characterizes advice-seeking posts.\nRelationship-focused discussions reflect real-world emotional stakes. Topics such as trust, infidelity, commitment anxiety, and major life transitions consistently dominate conversation volume. These discussions often signal real distress, making emotional modeling, conflict prediction, and supportive intervention especially valuable in this domain."
  },
  {
    "objectID": "conclusion.html#final-thoughts",
    "href": "conclusion.html#final-thoughts",
    "title": "Conclusion and Recommendations",
    "section": "Final Thoughts",
    "text": "Final Thoughts\nThis project demonstrates the value of integrating large-scale behavioral analysis, linguistic modeling, and machine learning to understand complex online communities. By examining nearly ten million Reddit posts and comments, we uncovered clear patterns in when users seek advice, how they express emotion, and what kinds of relationship challenges prompt the most meaningful engagement. Our analyses reveal predictable temporal posting cycles, weak but consistent links between post length and engagement, distinct thematic structures in relationship storytelling, and measurable linguistic and behavioral markers that forecast both controversy and high community response. Beyond technical achievement, the work highlights how digital platforms serve as emotional support systems for millions of people navigating difficult personal experiences. The insights gained here not only inform better moderation and platform design but also underscore the importance of empathetic, responsible approaches to analyzing human-centered online data."
  },
  {
    "objectID": "conclusion.html#acknowledgments",
    "href": "conclusion.html#acknowledgments",
    "title": "Conclusion and Recommendations",
    "section": "Acknowledgments",
    "text": "Acknowledgments\n\nTeam Members:\n\nJiayi Peng\nKexin Lyu\nStacy Che\nYanan Wu\n\nCourse: DSAN 6000 Big Data Analytics\nTools: Apache Spark, PySpark, Quarto\nData Source: Reddit via Pushshift archives"
  },
  {
    "objectID": "eda.html",
    "href": "eda.html",
    "title": "Exploratory Data Analysis",
    "section": "",
    "text": "Milestone 1 Deliverable\n\n\n\nThis page is populated during Milestone 1 (Week 3) with EDA findings."
  },
  {
    "objectID": "eda.html#overview",
    "href": "eda.html#overview",
    "title": "Exploratory Data Analysis",
    "section": "Overview",
    "text": "Overview\nThis page presents exploratory data analysis of our Reddit dataset, addressing three key EDA business questions through statistical summaries, temporal patterns, and topic-level engagement visualizations.\nOur goal is to understand how relationship-related discussions evolve over time and which emotional or social themes drive community participation."
  },
  {
    "objectID": "eda.html#data-overview",
    "href": "eda.html#data-overview",
    "title": "Exploratory Data Analysis",
    "section": "Data Overview",
    "text": "Data Overview\n\nDataset Summary\n\n\n\n\n\n\n\n\n\n\ndata_type\ntotal_rows\nsize_gb\ndate_range_start\ndate_range_end\n\n\n\n\ncomments\n8,674,611\n1.62\n2023-06-01\n2024-07-31\n\n\nsubmissions\n1,149,649\n0.21\n2023-06-01\n2024-07-31\n\n\n\n\n\nText Quality Summary\n\n\n\ndata_type\nmissing_text\ntoo_short\ntoo_long\n\n\n\n\ncomments\n0\n13,880\n1,392\n\n\nsubmissions\n0\n646\n0\n\n\n\nKey Statistics - Total entries: ~9.8 M (8.7 M comments + 1.1 M submissions)\n- Date range: June 2023 – July 2024\n- Text coverage: &gt; 99.9 % complete, minimal length anomalies\nInterpretation:\nThe dataset is clean and well-structured for downstream NLP analysis. Extremely short or long entries form less than 0.2 % of the corpus, ensuring consistent textual quality."
  },
  {
    "objectID": "eda.html#business-question-1-time-pattern-of-posting-activities",
    "href": "eda.html#business-question-1-time-pattern-of-posting-activities",
    "title": "Exploratory Data Analysis",
    "section": "Business Question 1: Time Pattern of Posting Activities",
    "text": "Business Question 1: Time Pattern of Posting Activities\nQuestion: How do posting behaviors vary by season, hour, and day of week?\n\nAnalysis Approach\nTo explore temporal engagement trends in Reddit relationship discussions, we examined post and comment volumes across multiple time dimensions:\n\nTemporal Aggregation:\nExtracted month, day_of_week, and hour_of_day from each post’s UTC timestamp.\nMonthly Trends:\nGrouped posts by month (June 2023 – July 2024) to reveal long-term seasonal dynamics.\nHourly × Weekly Patterns:\nComputed a cross-tabulation of posting frequency by hour and weekday to detect daily and weekly engagement rhythms.\nVisualization:\n\nLine chart – monthly posting trend (2023–2024)\n\nHeatmap – posting activity by hour × weekday\n\nSummary table – average posts and comments per weekday\n\n\n\n\nFindings\n \nKey Insights:\n\nStrong seasonality: Posting activity peaks between June – August 2023, exceeding 150 k posts per month. Engagement gradually declines through late 2023 and reaches its lowest levels in April–May 2024, then slightly recovers in early summer 2024.\nDaily rhythm: The heatmap shows clear circadian behavior—activity rises sharply after 16:00 UTC and peaks between 18:00–23:00 UTC, aligning with evening hours in North America and Europe.\nWeekday dynamics: Moderate variation across weekdays, with slightly higher engagement at the start of the week (Monday–Tuesday), possibly reflecting users seeking advice after weekend experiences."
  },
  {
    "objectID": "eda.html#business-question-2-post-length-engagement-dynamics",
    "href": "eda.html#business-question-2-post-length-engagement-dynamics",
    "title": "Exploratory Data Analysis",
    "section": "Business Question 2: Post Length & Engagement Dynamics",
    "text": "Business Question 2: Post Length & Engagement Dynamics\nQuestion: How do post lengths and engagement (score / comment count) correlate over time?\n\nAnalysis Approach\nTo assess the potential relationship between post length and engagement in Reddit discussions, we conducted the following steps:\n\nText Length Calculation: Combined title and selftext fields into a single text body and computed post_length as the total number of words.\nLength Categorization: Binned posts into three categories based on word count:\n\nShort: &lt; 100 words\nMedium: 100–500 words\nLong: &gt; 500 words\n\nCorrelation Analysis: Computed Pearson correlation coefficients between post_length, score, and num_comments for the full dataset.\nVisualization:\n\nHistogram – distribution of post lengths\nScatter plot – relationship between post length and number of comments (with binned averages)\n\n\n\n\nFindings\n \nKey Insights:\n\nPost lengths are highly skewed: the median length is only 18 words, but the 95th percentile reaches 635 words, and the maximum exceeds 8000 words.\nPosts between 100-500 words tend to receive the highest average number of comments, suggesting that mid-length content is the sweet spot for engagement.\nCorrelations between post length and engagement metrics are weak overall, implying the relationship is non-linear and may depend on additional contextual factors like content quality or topic."
  },
  {
    "objectID": "eda.html#business-question-3-topic-type-vs-average-comments",
    "href": "eda.html#business-question-3-topic-type-vs-average-comments",
    "title": "Exploratory Data Analysis",
    "section": "Business Question 3: Topic Type vs Average Comments",
    "text": "Business Question 3: Topic Type vs Average Comments\nQuestion: Which types of posts (“confession”, “breakup”, “family”, “marriage”, etc.) receive the most comments on average? ### Analysis Approach\nTo identify which themes in relationship discussions attract the most user engagement, we used keyword-based topic labeling and computed the average number of comments per topic category.\n\nTopic labeling:\nWe created a topic_label variable using regex keyword detection, mapping each submission title or text to one of several predefined categories such as marriage, breakup, dating, confession, family, and other.\nAggregation:\nFor each topic, we computed the mean number of comments per submission (avg_num_comments), along with basic descriptive counts.\nVisualization:\nWe produced a bar chart showing topic_label vs. avg_num_comments and an optional summary table.\n\n\nFindings\n\nKey Insights:\n\nMarriage posts receive the highest engagement, averaging nearly 14 comments each. This suggests that long-term relational commitments spark deeper discussions and community advice sharing.\nBreakup and dating topics maintain moderate activity (≈6 comments per post), indicating consistent but less intense engagement.\nConfession and family posts tend to receive fewer responses, possibly due to their private or introspective tone.\nThe “other” category, though the largest by count, generates the least engagement—highlighting that emotional relevance, not volume, drives attention in online relationship discourse."
  },
  {
    "objectID": "eda.html#summary",
    "href": "eda.html#summary",
    "title": "Exploratory Data Analysis",
    "section": "Summary",
    "text": "Summary\n\nAnswers to EDA Business Questions\n\nHow do posting behaviors vary by season, hour, and day of week?: Posting activity shows clear seasonal and daily cycles, peaking during summer months and during evening hours in major Western time zones, with slightly higher engagement early in the week.\nHow do post lengths and engagement (score / comment count) correlate over time?: Post length is positively correlated with engagement, but only weakly. Longer posts receive more comments on average than short posts, yet the overall correlation between length and score/comments remains below 0.1, suggesting other factors primarily drive user responses.\nWhich types of posts (“confession”, “breakup”, “family”, “marriage”, etc.) receive the most comments on average?: Among all relationship-related post types, “marriage” discussions receive by far the highest engagement, with an average of 13.88 comments per post — more than double that of any other category. Posts about breakups and dating follow, each averaging around 6 comments, indicating moderate but consistent community interaction.\n\n\n\nKey Takeaways\n\nActivity spikes sharply between 18:00–23:00 UTC, consistent with evening usage in North America and Europe, and reaches its highest seasonal volume in June–August, then declines into spring before rebounding in early summer.\nWhile long posts tend to draw more comments on average, post length is only weakly associated with engagement overall, which suggests that content plays a larger role than verbosity.\nOur EDA analysis suggests that posts on marriage stand out as the most discussed category, indicating that users are particularly responsive to conversations involving long-term commitment, conflict, or marital dilemmas. Breakup and dating discussions also generate relatively high engagement, reflecting active community interest in transitional or uncertain relationship stages. In contrast, family and confession topics receive less interaction, suggesting these themes may be more personal or situational, evoking fewer shared experiences from the broader audience, or that these conversations tend not to be a focus of our particular subreddit. The overall findings suggest that the subreddit’s engagement dynamics are driven by the emotional intensity and relational stakes of each topic, with posts addressing key relationship milestones like marriage and breakups fostering the richest discussions and advice exchanges.\n\n\n\n\n\n\n\n\nCode and Data\n\n\n\nAll EDA code is available in code/eda/ directory. Results are saved in data/csv/ and visualizations in data/plots/."
  },
  {
    "objectID": "ml.html",
    "href": "ml.html",
    "title": "Machine Learning",
    "section": "",
    "text": "Milestone 3 Deliverable\n\n\n\nThis page is populated during Milestone 3 (Week 6) with ML findings."
  },
  {
    "objectID": "ml.html#overview",
    "href": "ml.html#overview",
    "title": "Machine Learning",
    "section": "Overview",
    "text": "Overview"
  },
  {
    "objectID": "ml.html#business-question-8-can-we-predict-whether-a-reddit-comment-will-be-controversial",
    "href": "ml.html#business-question-8-can-we-predict-whether-a-reddit-comment-will-be-controversial",
    "title": "Machine Learning",
    "section": "Business Question 8: Can we predict whether a Reddit comment will be “controversial”?",
    "text": "Business Question 8: Can we predict whether a Reddit comment will be “controversial”?\nQuestion: Can we use comment-level metadata and simple text-derived features to predict whether a Reddit comment in r/relationship_advice will be controversial (i.e., produce disagreement reflected by Reddit’s controversiality flag)?\n\n\nProblem Formulation\n\nTask Type: Binary Classification\nTarget Variable:\n\ncontroversiality (1 = controversial comment, 0 = non-controversial)\n\n\n\n\n\nFeature Engineering\nFeatures Used:\n\n1. Text-Derived Features\n\nbody_length — number of characters in the comment\nnum_words — word count (proxy for comment complexity)\npunctuation_count — emotional punctuation (“?”, “!”)\n(binary) contains_question — whether the comment includes a question tone\n\n\n\n2. Behavioral / Engagement Features\n\nscore — upvote score\ngilded — comment received Reddit awards\nis_top_level — whether the comment is a top-level reply\nhour — posting hour extracted from created_utc\n(optional) negativity — presence of negative keywords\n\n\n\n3. Thread Structure Features\n\nparent_id → identifies if comment belongs to deep threads where disputes occur\nis_top_level (explicit) captures structural location in the thread\n\n\n\n\n\nModel Performance\n\nAUC-ROC: 0.76\n\nEven with lightweight engineered features (no TF-IDF, no embeddings), the model achieves strong AUC = 0.76, indicating that metadata + simple linguistic cues already contain substantial signal about comment controversy.\n\n\n\nFeature Importance\n\n\n\n\n\n\n\nFeature\nInterpretation\n\n\n\n\ngilded (1.86)\nAwarded comments are far more likely to be controversial—strong emotional or opinionated content tends to receive awards.\n\n\nis_top_level (–0.69)\nTop-level comments are significantly less controversial; arguments tend to occur in deeper thread replies.\n\n\nnum_words (–0.11)\nShorter comments tend to be more controversial; long advice-style comments are calmer and less debated.\n\n\npunctuation_count (+0.01)\nEmotional punctuation indicates elevated disagreement potential.\n\n\nscore (–0.008)\nComments with high upvotes reflect community consensus → less controversy.\n\n\nhour, body_length\nMinimal predictive signal."
  },
  {
    "objectID": "ml.html#business-question-9-can-we-predict-which-reddit-relationship-posts-will-receive-high-engagement",
    "href": "ml.html#business-question-9-can-we-predict-which-reddit-relationship-posts-will-receive-high-engagement",
    "title": "Machine Learning",
    "section": "Business Question 9: Can we predict which Reddit relationship posts will receive high engagement?",
    "text": "Business Question 9: Can we predict which Reddit relationship posts will receive high engagement?\nQuestion: Can early linguistic and behavioral signals in a relationship-focused Reddit post help us predict which posts will spark large-scale community engagement and conversation?\n\nProblem Formulation\n\nTask Type: Binary Classification\nTarget Variable: label_high_engagement (1 = top 25% by number of comments, 0 = otherwise)\nEvaluation Metric: AUC (primary), Accuracy, Precision, Recall, F1 score\n\n\n\nFeature Engineering\nFeatures Used:\n\n\nText-Based Features\n\n\nBag-of-Words (CountVectorizer, vocab=10k)\nToken count\nSentence count\nPresence of question mark\n\n\nTemporal Features\n\n\nPosting hour\nDay of week\nWeekend indicator\n\n\nComment-Derived Aggregates\n\n\nMean / max / sum of comment scores\nMean / max / sum of comment text length\nNumber of unique commenters\nControversiality metrics\n\n\n\n\nModel Performance\n\nROC Curve\n\n\n\nConfusion Matrix\n\n\n\nProbability Distribution by True Label\n\nResults:\n\nAccuracy: 0.6189\nPrecision: (Pred=1) 153 / (153 + 276) ≈ 0.356\nRecall: (True=1) 153 / (153 + 109) ≈ 0.584\nF1 Score: 0.6417\nAUC: 0.654\n\n\n\n\nModel Comparison\n\n\n\n\n\n\n\n\n\n\n\n\n\nModel\nFeatures Used\nHandling Imbalance\nAUC\nAccuracy\nPrecision\nRecall\nF1 Score\n\n\n\n\nLogistic Regression (Final)\nNumeric + BoW + Comment Features\nClass Weighting\n0.656\n0.619\n0.469\n0.604\n0.642\n\n\nRandom Forest (Baseline)\nNumeric + BoW + Comment Features\nOversampling\n0.612\n0.512\n—\n—\n0.347\n\n\nLogistic Regression (Simple)\nNumeric Only\nNone\n—\n—\n—\n—\n—\n\n\nNaive Baseline (Majority)\nNo features\nNone\n0.500\n0.75\n0\n0\n0\n\n\n\n\n\nFeature Importance (Top 10 Predictors)\n\n\n\n\n\n\n\n\nFeature\nImportance\nInterpretation\n\n\n\n\ncomment_author_nunique\n0.4821\nMore unique commenters strongly predict high engagement; diverse participation drives discussion.\n\n\ncomment_score_sum\n0.3567\nHigher total comment scores indicate community interest and validation, correlating with engagement.\n\n\nbow_features\n0.3124\nBag-of-Words captures topic and emotional language; certain words/phrases attract more responses.\n\n\ncomment_len_sum\n0.2894\nLonger total comment text suggests in-depth discussions, a hallmark of high-engagement posts.\n\n\ncomment_score_max\n0.2341\nA highly-upvoted comment signals a resonant or controversial point that draws further attention.\n\n\ncomment_contro_sum\n0.1956\nControversial comments spark debate, leading to more replies and overall engagement.\n\n\ncomment_len_mean\n0.1724\nLonger average comments indicate thoughtful discussion rather than brief reactions.\n\n\ntitle_has_question_mark\n0.1489\nQuestions in titles invite responses; users are more likely to engage with direct questions.\n\n\nhas_question_mark\n0.1367\nQuestion marks in body text similarly prompt reader responses and advice-giving behavior.\n\n\ncomment_score_mean\n0.1245\nHigher average comment quality reflects sustained community interest."
  },
  {
    "objectID": "ml.html#business-question-10-can-we-predict-daily-post-volume-in-rrelationship_advice",
    "href": "ml.html#business-question-10-can-we-predict-daily-post-volume-in-rrelationship_advice",
    "title": "Machine Learning",
    "section": "Business Question 10: Can We Predict Daily Post Volume in r/relationship_advice?",
    "text": "Business Question 10: Can We Predict Daily Post Volume in r/relationship_advice?\nQuestion: Can we use historical posting trends, time-based seasonality, and lagged behavioral patterns to forecast how many posts the subreddit will receive each day?\n\n\nProblem Formulation\n\nTask Type: Regression\nTarget Variable:\n\nn_posts - number of reddit submissions per day\n\n\n\n\n\nFeature Engineering\nFeatures Used:\n\n1. Time-Based Features\n\nday_of_week - 1~7\nmonth\nday_of_year\nis_weekend - binary\nfourier seasonal terms` - capture smooth yearly cycles (fourier_sin_1, fourier_cos_1)\n\n\n\n2. Lag Features\n\nlag_1, lag_2, lag_3 - short-term lag\nlag_7 - weekly seasonality\nlag_14, lag_21, lag_28 - multi-week cycles\n\n\n\n3. Rolling Statistics\n\nrolling_mean_7, rolling_mean_14, rolling_mean_30\nrolling_std_7, rolling_std_14\n\n\n\n\n\nModel Performance\n\n\n\nModel\nRMSE\nMAE\nR²\n\n\n\n\nRidge Regression\n78.62\n65.04\n0.559\n\n\nElasticNet\n82.02\n67.80\n0.521\n\n\nRandom Forest\n93.29\n74.27\n0.380\n\n\nXGBoost\n110.17\n91.21\n0.135\n\n\n\n\n\n\nFeature Importance\nAlthough Ridge achieved the best performance, Random Forest provides the most interpretable feature importances:\n\n\n\nFeature\nImportance\n\n\n\n\nlag_1\n0.213\n\n\nrolling_mean_14\n0.193\n\n\nrolling_mean_7\n0.165\n\n\nlag_2\n0.156\n\n\nrolling_mean_30\n0.082\n\n\n\n\n\n\nPrediction Behavior\nBelow is the test-set prediction plot generated from the best model:\n\n\nThe model successfully captures the weekly seasonal pattern.\nPredicted values tend to be slightly smoother and lower variance than actual data.\nSudden peaks in real data are harder to capture without external features."
  },
  {
    "objectID": "ml.html#summary",
    "href": "ml.html#summary",
    "title": "Machine Learning",
    "section": "Summary",
    "text": "Summary\n\nAnswers to ML Business Questions\n1.Can we use comment-level metadata and simple text-derived features to predict whether a Reddit comment in r/relationship_advice will be controversial (i.e., produce disagreement reflected by Reddit’s controversiality flag)?: Yes. Using metadata and simple linguistic features, a Logistic Regression model achieves AUC ≈ 0.76. Key predictors include comment depth, awards, and emotionally expressive writing (punctuation, short opinionated phrasing).\n2.Can early linguistic and behavioral signals in a relationship-focused Reddit post help us predict which posts will spark large-scale community engagement and conversation? Yes. A lightweight, class-balanced model predicts high-engagement posts with AUC ≈ 0.65, successfully identifying a majority of posts in the top 25% comment-count group. Features related to community interaction (e.g.unique commenters) contributes meaningfully.\n3.Can we use historical posting trends, time-based seasonality, and lagged behavioral patterns to forecast how many posts the subreddit will receive each day?: Yes. Using lag-based and rolling temporal features, Ridge Regression achieves R² ≈ 0.56, showing that over half of day-to-day variation in posting activity can be explained by historical behavioral cycles. Yesterday’s volume, short-term weekly cycles, and rolling 14-30 day trends matters most.\n\n\n\nBusiness Implications\n\nEarly Detection of Conflict or High-Risk Threads:\nModels predicting controversy help moderators identify emerging disputes and intervene before discussions escalate.\nUnderstanding What Triggers Engagement or Disagreement:\nEmotional punctuation, short reactive replies, and awards signal posts likely to generate strong reactions, guiding content strategy and moderation rules.\nPrioritizing Moderation Resources:\nHigh-engagement and high-conflict posts often require more moderator attention. Predictive signals enable smarter scheduling and targeted monitoring.\nSupporting Users in Distress:\nHighly emotional or high-engagement posts often reflect relationship crises; platforms can direct such posts toward peer helpers or mental-health support workflows.\nForecasting Community Activity:\nDaily volume predictions enable:\n\nanomaly detection (e.g., trending topics, external events)\ndynamic autoscaling of NLP/ML pipelines\n\nplanning moderator staffing during expected surges\n\nImproved Content Ranking & Curation:\nEngagement and conflict predictions can be integrated into ranking systems to surface meaningful discussions while downranking potential conflict spirals.\n\nTogether, these models provide a comprehensive toolkit for understanding and managing engagement dynamics in relationship-focused Reddit communities.\n\n\n\n\n\n\n\nTip\n\n\n\nAll ML code is in code/ml/ directory. Models saved in code/ml/models/."
  }
]