{"class":"org.apache.spark.ml.feature.RegexTokenizer","timestamp":1764110647868,"sparkVersion":"3.4.4","uid":"RegexTokenizer_ed7e7c866006","paramMap":{"minTokenLength":2,"pattern":"\\W+","inputCol":"clean_text","outputCol":"tokens","toLowercase":true},"defaultParamMap":{"minTokenLength":1,"pattern":"\\s+","outputCol":"RegexTokenizer_ed7e7c866006__output","gaps":true,"toLowercase":true}}
